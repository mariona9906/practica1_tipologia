{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095cff6d",
   "metadata": {},
   "source": [
    "# Practica 2 Tipologia y ciclo de vida de los datos \n",
    "## Dmytro Pravdyvets y Mariona Alberola "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ba0175",
   "metadata": {},
   "source": [
    "## 1. Descripción del dataset\n",
    "### ¿Por qué es importante y qué pregunta/problema pretende responder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca668a4",
   "metadata": {},
   "source": [
    "En esta practica vamos a continuar con el dataset generado en la practica anterior. Como hemos expliado previamente, la idea de estas dos practicas es automatizar la busqueda y seleccion de articulos cientificos de interes. \n",
    "\n",
    "Automatizacion de busqueda de infromacion relevante para un investigador es un proceso que puede beneficiar muchisimo a un cientifico ya que le permitira estar mas tiempo haciendo su trabajo que una maquina no puede hacer. \n",
    "\n",
    "En esta practica vamos a mirar cual es el porcentaje de papers que han aplicado ML y AI en el ambito de inmunologia, que algoritmos se han usado y si hay una tendencia de aumento de papers mas computacionales en los ultimos años. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346562f",
   "metadata": {},
   "source": [
    "## 2. Integración y selección de los datos de interés a analizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b21b3",
   "metadata": {},
   "source": [
    "En la anterior practica solo hemos trabajado con los articulos publicados en el año 2022, no obstante hemos pensado que seria mas interesante aumentar este numero y trabajar con papers desde el año 2020 hasta 2022. \n",
    "\n",
    "Recordemos las columnas de nuestro dataset:\n",
    "\n",
    "*Article*: Nombre del artículo científico.\n",
    "\n",
    "*Summary*: Resumen general de la investigación que se ha llevado a cabo.\n",
    "\n",
    "*Authors*: Nombre de los autores del artículo científico.\n",
    "\n",
    "*Date*: Fecha de publicación.\n",
    "\n",
    "*Access*: Si es de acceso público o se tiene que pagar para acceder al artículo.\n",
    "\n",
    "*Figure*: Una imagen representativa del estudio en cuestión.\n",
    "\n",
    "*Link paper*: Link del artículo científico, los artículos de acceso no público muestran el\n",
    "título del artículo y el resumen general del artículo.\n",
    "\n",
    "*TCR, BCR, T CELL, B CELL, NKC, CD4, CD8, DEEP LEARNING, MACHINE\n",
    "LEARNING y HLA*: palabras clave que nos interesan, en caso de que el estudio\n",
    "contenga esa palabra clave el valor va a ser 1 y en caso de no contenerla será 0.\n",
    "\n",
    "\n",
    "De estas columnas, los keywords es la parte mas interesante ya que nos permitira filltrar el data por los diferentes tipos de celulas (T y B cells) y ver cuantos papers ML y AI para hacer el analysis. \n",
    "\n",
    "Una vez tengamos lo papers de interes podemos aplicar NLP para ver la similaritud de los articulos. La idea que tenemos es a traves del abstract crear un heatmap con las distnacias entre los papers de las subcategorias como T-cell ML, B-cell ML por ejemplo para que nos sea mas facil ver papers parecidos a los papers que hemos detectado como papers de interes manualmente. Por ejemplo, hemos sacado todos los papers de interes y hemos leido el primero que va de clasificacion de celulas T CD4+ utilizando ML, con el heatmap podemos ver que otros papers son parecidos a este para no tener que leernos todos los papers de interes, sino solo los mas parecidos al nuestro paper de interes actual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab26a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1434b",
   "metadata": {},
   "source": [
    "## 3. Limpieza de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e87c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e6f05c0",
   "metadata": {},
   "source": [
    "## 4. Análisis de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16a75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93468f90",
   "metadata": {},
   "source": [
    "## 5. Representación de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b54eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92d3b185",
   "metadata": {},
   "source": [
    "## 6. Resolución del problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9448fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
